{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test the LSTM model \n",
    "\n",
    "The initial goal is to predict the highest month gainers\n",
    "We will also try for week and day\n",
    "Vary the input data to 50-100 days before prediction.\n",
    "Initial testing will be done on the AAPL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from sklearn.metrics import r2_score\n",
    "import pendulum\n",
    "import talib as ta\n",
    "\n",
    "\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "f = open('tradeData_22_08_2022.json')\n",
    "tradeDataJson = json.load(f)\n",
    "for k in tradeDataJson:\n",
    "    # only need the adjusted values so drop all the other columns\n",
    "    tradeDataJson[k]['data'] = pd.DataFrame(tradeDataJson[k]['data']).drop(columns=['close','high','low','open','volume','divCash','splitFactor']).set_index('date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add some features to the data\n",
    "- SME\n",
    "- RSI\n",
    "- SMA\n",
    "- Corr\n",
    "- SAR\n",
    "- ADX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>SMA</th>\n",
       "      <th>Corr</th>\n",
       "      <th>SAR</th>\n",
       "      <th>ADX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-20T00:00:00.000Z</th>\n",
       "      <td>37.028129</td>\n",
       "      <td>37.547714</td>\n",
       "      <td>36.496682</td>\n",
       "      <td>37.462303</td>\n",
       "      <td>206772956</td>\n",
       "      <td>44.908471</td>\n",
       "      <td>37.945588</td>\n",
       "      <td>0.439160</td>\n",
       "      <td>38.199591</td>\n",
       "      <td>16.080041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-21T00:00:00.000Z</th>\n",
       "      <td>36.392290</td>\n",
       "      <td>36.964071</td>\n",
       "      <td>36.240448</td>\n",
       "      <td>36.964071</td>\n",
       "      <td>146573528</td>\n",
       "      <td>35.197181</td>\n",
       "      <td>37.807032</td>\n",
       "      <td>0.711825</td>\n",
       "      <td>38.079162</td>\n",
       "      <td>17.105807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-22T00:00:00.000Z</th>\n",
       "      <td>36.036410</td>\n",
       "      <td>36.126567</td>\n",
       "      <td>35.720863</td>\n",
       "      <td>36.067253</td>\n",
       "      <td>184457696</td>\n",
       "      <td>28.337284</td>\n",
       "      <td>37.620314</td>\n",
       "      <td>0.830980</td>\n",
       "      <td>37.905967</td>\n",
       "      <td>18.743902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-25T00:00:00.000Z</th>\n",
       "      <td>35.718491</td>\n",
       "      <td>36.022175</td>\n",
       "      <td>35.388709</td>\n",
       "      <td>35.585629</td>\n",
       "      <td>175689336</td>\n",
       "      <td>25.273935</td>\n",
       "      <td>37.460405</td>\n",
       "      <td>0.923875</td>\n",
       "      <td>37.572863</td>\n",
       "      <td>21.411638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26T00:00:00.000Z</th>\n",
       "      <td>36.332977</td>\n",
       "      <td>36.518035</td>\n",
       "      <td>35.988960</td>\n",
       "      <td>36.010312</td>\n",
       "      <td>141883940</td>\n",
       "      <td>22.824782</td>\n",
       "      <td>37.200612</td>\n",
       "      <td>0.946329</td>\n",
       "      <td>37.202463</td>\n",
       "      <td>24.429570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           adjClose    adjHigh     adjLow    adjOpen  \\\n",
       "date                                                                   \n",
       "2017-09-20T00:00:00.000Z  37.028129  37.547714  36.496682  37.462303   \n",
       "2017-09-21T00:00:00.000Z  36.392290  36.964071  36.240448  36.964071   \n",
       "2017-09-22T00:00:00.000Z  36.036410  36.126567  35.720863  36.067253   \n",
       "2017-09-25T00:00:00.000Z  35.718491  36.022175  35.388709  35.585629   \n",
       "2017-09-26T00:00:00.000Z  36.332977  36.518035  35.988960  36.010312   \n",
       "\n",
       "                          adjVolume        RSI        SMA      Corr  \\\n",
       "date                                                                  \n",
       "2017-09-20T00:00:00.000Z  206772956  44.908471  37.945588  0.439160   \n",
       "2017-09-21T00:00:00.000Z  146573528  35.197181  37.807032  0.711825   \n",
       "2017-09-22T00:00:00.000Z  184457696  28.337284  37.620314  0.830980   \n",
       "2017-09-25T00:00:00.000Z  175689336  25.273935  37.460405  0.923875   \n",
       "2017-09-26T00:00:00.000Z  141883940  22.824782  37.200612  0.946329   \n",
       "\n",
       "                                SAR        ADX  \n",
       "date                                            \n",
       "2017-09-20T00:00:00.000Z  38.199591  16.080041  \n",
       "2017-09-21T00:00:00.000Z  38.079162  17.105807  \n",
       "2017-09-22T00:00:00.000Z  37.905967  18.743902  \n",
       "2017-09-25T00:00:00.000Z  37.572863  21.411638  \n",
       "2017-09-26T00:00:00.000Z  37.202463  24.429570  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL = tradeDataJson['AAPL']['data'].copy(deep=True)\n",
    "window = 10\n",
    "AAPL['RSI'] = ta.RSI(np.array(AAPL['adjClose'].shift(1)), timeperiod=window)\n",
    "AAPL['SMA'] = AAPL['adjClose'].shift(1).rolling(window=window).mean()\n",
    "AAPL['Corr'] = AAPL['adjClose'].shift(1).rolling(window=window).corr(AAPL['SMA'].shift(1))\n",
    "AAPL['SAR'] = ta.SAR(np.array(AAPL['adjHigh'].shift(1)), np.array(AAPL['adjLow'].shift(1)),\n",
    "                   0.2, 0.2)\n",
    "AAPL['ADX'] = ta.ADX(np.array(AAPL['adjHigh'].shift(1)), np.array(AAPL['adjLow'].shift(1)),\n",
    "                   np.array(AAPL['adjOpen']), timeperiod=window)\n",
    "\n",
    "AAPL.dropna(inplace=True)\n",
    "AAPL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x_and_y_sets(data,LOOKUP_STEP =1,N_STEPS =60):\n",
    "    n = LOOKUP_STEP  - 1\n",
    "    x_ray = []\n",
    "    y_ray = []\n",
    "\n",
    "    for i in range(N_STEPS ,len(data)-n):\n",
    "        x_ray.append(data[i-N_STEPS :i])\n",
    "        y_ray.append(data[i+n,1])\n",
    "\n",
    "    return np.array(x_ray), np.array(y_ray)\n",
    "\n",
    "    \n",
    "def generate_test_and_train(data,N_STEPS  = 60, LOOKUP_STEP =1,train_percentage=0.8):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaledData = scaler.fit_transform(data)\n",
    "    train_data = (scaledData[:int((scaledData.shape[0])*train_percentage)])\n",
    "    test_data = (scaledData[int((scaledData.shape[0])*train_percentage)-N_STEPS:])\n",
    "\n",
    "\n",
    "    x_train, y_train = generate_x_and_y_sets(train_data,LOOKUP_STEP =1,N_STEPS=N_STEPS)\n",
    "    x_test, y_test = generate_x_and_y_sets(test_data,LOOKUP_STEP =1,N_STEPS=N_STEPS)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test#, scaler\n",
    "\n",
    "\n",
    "dataDict = {}\n",
    "\n",
    "dataDict['n_steps_50-lookup_step_20'] = generate_test_and_train(AAPL, 50,20)\n",
    "dataDict['n_steps_50-lookup_step_5'] = generate_test_and_train(AAPL, 50,5)\n",
    "dataDict['n_steps_50-lookup_step_1'] = generate_test_and_train(AAPL, 50,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "model_n_steps_50_lookup_step_20 = create_model(50,10,loss = 'huber_loss',optimizer = 'adam')\n",
    "model_n_steps_50_lookup_step_5 = create_model(50,10,loss = 'huber_loss',optimizer = 'adam')\n",
    "model_n_steps_50_lookup_step_1 = create_model(50,10,loss = 'huber_loss',optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 3.4084e-04 - mean_absolute_error: 0.0185 - val_loss: 0.0014 - val_mean_absolute_error: 0.0459\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 3.4521e-04 - mean_absolute_error: 0.0184 - val_loss: 9.3807e-04 - val_mean_absolute_error: 0.0346\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 3.3537e-04 - mean_absolute_error: 0.0176 - val_loss: 0.0017 - val_mean_absolute_error: 0.0516\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 7s 452ms/step - loss: 3.6350e-04 - mean_absolute_error: 0.0189 - val_loss: 7.8938e-04 - val_mean_absolute_error: 0.0311\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 3.4392e-04 - mean_absolute_error: 0.0181 - val_loss: 4.3759e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 3.1990e-04 - mean_absolute_error: 0.0177 - val_loss: 6.4302e-04 - val_mean_absolute_error: 0.0276\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 3.6873e-04 - mean_absolute_error: 0.0191 - val_loss: 8.3111e-04 - val_mean_absolute_error: 0.0320\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 4.0658e-04 - mean_absolute_error: 0.0196 - val_loss: 0.0023 - val_mean_absolute_error: 0.0607\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 4.0280e-04 - mean_absolute_error: 0.0195 - val_loss: 0.0012 - val_mean_absolute_error: 0.0407\n",
      "Epoch 1/500\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 4.5253e-04 - mean_absolute_error: 0.0220 - val_loss: 6.9282e-04 - val_mean_absolute_error: 0.0290\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 4.7141e-04 - mean_absolute_error: 0.0220 - val_loss: 0.0016 - val_mean_absolute_error: 0.0474\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 4.1109e-04 - mean_absolute_error: 0.0202 - val_loss: 0.0019 - val_mean_absolute_error: 0.0535\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 4.1463e-04 - mean_absolute_error: 0.0204 - val_loss: 6.3269e-04 - val_mean_absolute_error: 0.0284\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 4.3955e-04 - mean_absolute_error: 0.0211 - val_loss: 6.3802e-04 - val_mean_absolute_error: 0.0279\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 4.6498e-04 - mean_absolute_error: 0.0214 - val_loss: 6.2515e-04 - val_mean_absolute_error: 0.0277\n",
      "Epoch 1/500\n",
      "15/15 [==============================] - 13s 528ms/step - loss: 0.0212 - mean_absolute_error: 0.1421 - val_loss: 0.0067 - val_mean_absolute_error: 0.1048\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 7s 458ms/step - loss: 0.0020 - mean_absolute_error: 0.0479 - val_loss: 0.0019 - val_mean_absolute_error: 0.0494\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 7s 456ms/step - loss: 8.9252e-04 - mean_absolute_error: 0.0294 - val_loss: 0.0011 - val_mean_absolute_error: 0.0389\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 7s 458ms/step - loss: 6.2948e-04 - mean_absolute_error: 0.0251 - val_loss: 0.0015 - val_mean_absolute_error: 0.0426\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 7s 471ms/step - loss: 6.5533e-04 - mean_absolute_error: 0.0258 - val_loss: 0.0012 - val_mean_absolute_error: 0.0392\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 6.3306e-04 - mean_absolute_error: 0.0247 - val_loss: 0.0011 - val_mean_absolute_error: 0.0372\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 7s 463ms/step - loss: 5.4929e-04 - mean_absolute_error: 0.0231 - val_loss: 0.0017 - val_mean_absolute_error: 0.0473\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 5.1544e-04 - mean_absolute_error: 0.0223 - val_loss: 0.0011 - val_mean_absolute_error: 0.0361\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 7s 481ms/step - loss: 5.7512e-04 - mean_absolute_error: 0.0239 - val_loss: 0.0015 - val_mean_absolute_error: 0.0439\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 5.5453e-04 - mean_absolute_error: 0.0230 - val_loss: 0.0013 - val_mean_absolute_error: 0.0402\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 5.7113e-04 - mean_absolute_error: 0.0236 - val_loss: 9.2959e-04 - val_mean_absolute_error: 0.0337\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss',patience=3)\n",
    "\n",
    "model_n_steps_50_lookup_step_20_history = model_n_steps_50_lookup_step_20.fit(dataDict['n_steps_50-lookup_step_20'][0], dataDict['n_steps_50-lookup_step_20'][1],\n",
    "                                                                                batch_size=64,\n",
    "                                                                                epochs=500,\n",
    "                                                                                validation_data=(dataDict['n_steps_50-lookup_step_20'][2], dataDict['n_steps_50-lookup_step_20'][3]),\n",
    "                                                                                callbacks=[callback],\n",
    "                                                                                verbose=1)\n",
    "\n",
    "model_n_steps_50_lookup_step_5_history = model_n_steps_50_lookup_step_5.fit(dataDict['n_steps_50-lookup_step_5'][0], dataDict['n_steps_50-lookup_step_5'][1],\n",
    "                                                                                batch_size=64,\n",
    "                                                                                epochs=500,\n",
    "                                                                                validation_data=(dataDict['n_steps_50-lookup_step_5'][2], dataDict['n_steps_50-lookup_step_5'][3]),\n",
    "                                                                                callbacks=[callback],\n",
    "                                                                                verbose=1)\n",
    "\n",
    "model_n_steps_50_lookup_step_1_history = model_n_steps_50_lookup_step_1.fit(dataDict['n_steps_50-lookup_step_1'][0], dataDict['n_steps_50-lookup_step_1'][1],\n",
    "                                                                                batch_size=64,\n",
    "                                                                                epochs=500,\n",
    "                                                                                validation_data=(dataDict['n_steps_50-lookup_step_1'][2], dataDict['n_steps_50-lookup_step_1'][3]),\n",
    "                                                                                callbacks=[callback],\n",
    "                                                                                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91a8ff8349cc7a23d1ca74cc182c5776a2f33f77f09c5bf53def8638bc37bbae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
